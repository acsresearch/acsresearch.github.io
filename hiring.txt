2:I[2058,["807","static/chunks/807-2fc36657cdfdd175.js","101","static/chunks/101-6320b452af5c9a08.js","931","static/chunks/app/page-2f08b52657019d14.js"],"default"]
4:I[9986,[],""]
6:I[3582,[],""]
7:"$Sreact.strict_mode"
8:"$Sreact.suspense"
9:I[1646,["185","static/chunks/app/layout-5274a54cbda7604f.js"],"default"]
3:T36f1,<p>ACS Research is hiring for several full-time research positions focused on understanding and navigating
the systemic risks posed by advanced AI. We are looking for exceptional researchers to join our team.</p>
<p>Currently, we are hiring for three roles:</p>
<ul>
<li><a href="#research-fellow---gradual-disempowerment">Research Fellow - Gradual Disempowerment</a></li>
<li><a href="#researcher---llm-psychology--sociology">Researcher - LLM Psychology &#x26; Sociology</a></li>
<li><a href="#machine-learning-researcher---ai-psychology--agent-foundations">Machine Learning Researcher - AI Psychology &#x26; Agent Foundations</a></li>
</ul>
<p><a href="https://forms.gle/JxMbd9WBP6DiRezQA">Apply</a></p>
<p>Location: Prague, London or San Francisco Bay Area</p>
<hr>
<h2>Research Fellow - Gradual Disempowerment <a name="research-fellow---gradual-disempowerment"></a></h2>
<p>This is a full-time role focused on advancing our understanding of systemic existential risks from incremental AI development. The position offers a unique opportunity to conduct cutting-edge research on the <strong>gradual disempowerment</strong> of humanity through the displacement of human participation in societal systems. The initial appointment is for 1 or 2 years, with a competitive salary.</p>
<h3>About the Role</h3>
<p>As a Research Fellow, you will work on fundamental questions at the intersection of AI safety, macrostrategy, and civilizational dynamics. This role is ideal for <strong>polymaths</strong> who can navigate between technical, economic, and sociotechnical domains to understand how AI proliferation might reshape the foundations of human society.</p>
<p>You will have significant intellectual freedom to pursue your own research directions within our broad agenda. Your work may include:</p>
<ul>
<li><strong>Theoretical research</strong> on multi-agent dynamics, civilizational-scale alignment, and the formal modeling of societal systems.</li>
<li><strong>Economical modelling</strong> of disempowerment dynamics.</li>
<li><strong>Empirical studies</strong> of cultural dynamics in AI systems.</li>
<li><strong>Historical analysis</strong> of technological transitions, power shifts, and the stability of social institutions.</li>
<li><strong>Mechanism design</strong> for governance structures and economic systems that maintain human agency.</li>
<li><strong>Technical work</strong> on AI capabilities that complement rather than replace human capabilities.</li>
</ul>
<h3>Areas of Research Interest</h3>
<p>We are particularly interested in candidates who can contribute to one or more of the following research areas:</p>
<ol>
<li><strong>Civilizational-Scale Alignment</strong>
<ul>
<li>Formal models of the bidirectional influence between individuals and societal systems.</li>
<li>Understanding how to maintain alignment between powerful technological systems and human values.</li>
</ul>
</li>
<li><strong>Multi-Agent Dynamics &#x26; Emergent Behavior</strong>
<ul>
<li>Simulating large numbers of AI agents to understand cultural and collective dynamics.</li>
<li>Studying cooperation, coordination, and equilibrium selection in AI populations.</li>
</ul>
</li>
<li><strong>Measuring &#x26; Monitoring Disempowerment</strong>
<ul>
<li>Developing indicators and metrics for human influence across different domains.</li>
<li>Creating early warning systems for gradual disempowerment.</li>
</ul>
</li>
<li><strong>Historical &#x26; Comparative Analysis</strong>
<ul>
<li>Examining technological transitions like the industrial revolution and the internet.</li>
<li>Analyzing power shifts and systemic changes in history.</li>
</ul>
</li>
<li><strong>Human-AI Complementarity</strong>
<ul>
<li>Developing agendas for human-empowering technology that augment rather than replace human capabilities.</li>
<li>Understanding the window where human+AI outperforms either alone.</li>
</ul>
</li>
</ol>
<h3>Qualifications and Selection Criteria</h3>
<p>We seek exceptional researchers from diverse backgrounds, particularly polymaths comfortable working across multiple disciplines.</p>
<ul>
<li><strong>Relevant Backgrounds:</strong> Physics, Machine Learning, Economics, Cultural Evolution, Philosophy, Political Science/Governance, Mathematics, History.</li>
</ul>
<h4>Essential Criteria</h4>
<ul>
<li>Ability to produce exceptional research in complex domains.</li>
<li>Skills in synthesizing insights across multiple disciplines.</li>
<li>Ability to think at multiple scales—from individual agents to civilizational dynamics.</li>
<li>Intellectual courage to work on unconventional ideas.</li>
<li>Self-direction and ability to identify high-impact research directions.</li>
<li>Willingness to travel.</li>
</ul>
<h4>Desirable Qualities</h4>
<ul>
<li>Experience with SOTA AI.</li>
<li>A track record of original thinking.</li>
<li>Experience with remote collaboration.</li>
<li>Comfort with uncertainty and working on pre-paradigmatic problems.</li>
</ul>
<h3>Terms and Conditions</h3>
<ul>
<li><strong>Duration:</strong> Initial appointment for 1 or 2 years, with the possibility of extension.</li>
<li><strong>Location:</strong> Prague (Czech Republic), London (United Kingdom), or San Francisco Bay Area (United States).</li>
<li><strong>Compensation:</strong> $80-200k USD based on location and experience.</li>
<li><strong>Benefits:</strong> Research budget, flexible working arrangements, and intellectual freedom.</li>
</ul>
<h3>How to Apply</h3>
<p>To apply, please submit the following by <strong>October 15th</strong>:</p>
<ul>
<li><strong>Cover Letter</strong> (max 2 pages) explaining your motivation, interest in gradual disempowerment, relevant experience, and your potential research vision.</li>
<li><strong>CV</strong>.</li>
<li><strong>Writing Sample</strong> of your best research or analytical writing.</li>
<li><strong>References:</strong> Contact information for 2 references.</li>
</ul>
<p>The preferred start date is December 2025 or January 2026.</p>
<p><a href="https://forms.gle/JxMbd9WBP6DiRezQA">Apply</a></p>
<hr>
<h2>Researcher - LLM Psychology &#x26; Sociology <a name="researcher---llm-psychology--sociology"></a></h2>
<p>This is a full-time role focused on pioneering the empirical study of AI “psychology” and "sociology". This is a unique opportunity to design and execute first-of-their-kind experiments exploring the emergent group dynamics and internal states of large language models. The initial appointment is for 1 or 2 years with a competitive salary.</p>
<h3>About the Role</h3>
<p>As a Research Experimentalist, you will join a new team testing novel hypotheses about the behavior of interacting LLM agents. The role is for someone with a strong intuitive understanding of LLMs and an ability to combine insights from different fields in unconventional ways.</p>
<p>Your work will include:</p>
<ul>
<li><strong>Experimental Design:</strong> Creating controlled environments to test hypotheses about LLM behavior.</li>
<li><strong>Empirical Studies:</strong> Running experiments to investigate phenomena like LLM introspection, persona transfer, viral mindset propagation, and emergent cooperation.</li>
<li><strong>Dissemination:</strong> Communicating findings to the broader AI safety and machine learning communities.</li>
</ul>
<h3>Core Research Projects</h3>
<p>You will have significant intellectual freedom to design experiments within our core research streams:</p>
<ul>
<li><strong>Inter-Agent Dynamics: Character Migration &#x26; Infectious Mindsets:</strong> This stream examines the interactions and social dynamics of LLMs. We may test the transferability of personas between models or investigate if ideologies can propagate virally between interacting LLMs.</li>
<li><strong>Intra-Agent Dynamics: Self-Concept &#x26; Character Switches:</strong> This workstream investigates how LLMs model their own identity and how self-concepts can shift. We may create "model organisms" for studying character switches or design introspective characters to reveal internal LLM states.</li>
</ul>
<h3>Qualifications and Selection Criteria</h3>
<p>We are seeking exceptional individuals who are comfortable working on pre-paradigmatic problems and have a deep curiosity about the inner workings of AI systems.</p>
<ul>
<li><strong>Relevant Backgrounds:</strong> Cognitive Science, Physics, Psychology/Sociology, Philosophy, Machine Learning.</li>
</ul>
<h4>Essential Criteria</h4>
<ul>
<li>Demonstrated ability to interact with LLMs in skillful ways—an intuitive "feel" for LLM behavior.</li>
<li>Strong hands-on experience with SOTA AI.</li>
<li>Ability to engage with ML at the level of fine-tuning LLMs or creating synthetic datasets.</li>
<li>Ambition to translate intuitions into replicable findings.</li>
<li>Self-direction and the ability to work effectively in a small, focused team.</li>
</ul>
<h4>Desirable Qualities</h4>
<ul>
<li>A track record of original, unconventional thinking.</li>
<li>Experience with multi-agent systems or simulations.</li>
<li>Interest in the intersection of technical AI and insights from the humanities or social sciences.</li>
</ul>
<h3>Terms and Conditions</h3>
<ul>
<li><strong>Duration:</strong> Initial appointment for 1 or 2 years.</li>
<li><strong>Location:</strong> Prague (Czech Republic), London (United Kingdom), or San Francisco Bay Area (United States). The project is online-first.</li>
<li><strong>Compensation:</strong> $80-200k USD based on location and experience.</li>
<li><strong>Benefits:</strong> Research budget for API credits and compute, flexible work arrangements, and intellectual freedom.</li>
</ul>
<h3>How to Apply</h3>
<p>To apply, please submit the following by <strong>October 15th</strong>:</p>
<ul>
<li><strong>Cover Letter</strong> (max 2 pages) explaining your motivation, your perspective on one of the research themes, and how your past experience makes you a good fit.</li>
<li><strong>CV</strong>.</li>
</ul>
<p>The preferred start date is December 2025 or January 2026.</p>
<h2><a href="https://forms.gle/JxMbd9WBP6DiRezQA">Apply</a></h2>
<h2>Machine Learning Researcher - AI Psychology &#x26; Agent Foundations <a name="machine-learning-researcher---ai-psychology--agent-foundations"></a></h2>
<p>This full-time role is focused on building the robust experimental frameworks and ML systems needed to investigate the emergent "psychological" and "sociological" dynamics of AI agents. You will be the <strong>technical cornerstone</strong> of a pioneering research team, responsible for designing and implementing training, fine-tuning, and analysis pipelines. This is an initial 2-year appointment with a competitive salary.</p>
<h3>About the Role</h3>
<p>As the Machine Learning Researcher, you will provide the technical and methodological rigor for our team's explorations into LLM psychology. You will be responsible for translating high-level ideas into concrete ML experiments, mastering the entire experimental lifecycle from data preparation to applying interpretability tools. This role is ideal for a universalist ML researcher with experience in open-weights models and reinforcement learning.</p>
<p>Your core responsibilities will include:</p>
<ul>
<li><strong>Experimental Infrastructure:</strong> Designing and building scalable training and evaluation pipelines for single and multi-agent LLM simulations.</li>
<li><strong>Model Conditioning:</strong> Implementing state-of-the-art fine-tuning and reinforcement learning techniques to instill specific personas and behaviors in open-weights models.</li>
<li><strong>Interpretability &#x26; Analysis:</strong> Applying interpretability methods to find mechanistic explanations for observed emergent behaviors.</li>
<li><strong>Metric Development:</strong> Collaborating with the team to design novel metrics for evaluating abstract concepts like "persona fidelity" or "mindset propagation".</li>
<li><strong>Publication:</strong> Taking a leading role in writing and publishing the team's findings in top-tier ML conferences.</li>
</ul>
<h3>Qualifications and Selection Criteria</h3>
<p>We are looking for a researcher with a strong technical foundation and a desire to apply their skills to a new and challenging problem domain.</p>
<ul>
<li><strong>Relevant Backgrounds:</strong> Machine Learning, Reinforcement Learning, Natural Language Processing, Computer Science.</li>
</ul>
<h4>Essential Criteria</h4>
<ul>
<li>Hands-on experience with the full lifecycle of training, fine-tuning, and evaluating LLMs, especially open-weights models.</li>
<li>Proficiency with standard ML frameworks and the surrounding software ecosystem.</li>
<li>Ability to translate high-level research questions into concrete technical implementations.</li>
<li>Interest in working on non-traditional questions using frames from cognitive science, sociology, or psychology.</li>
</ul>
<h4>Desirable Qualities</h4>
<ul>
<li>Experience with interpretability tools and techniques.</li>
</ul>
<h3>Terms and Conditions</h3>
<ul>
<li><strong>Duration:</strong> Initial appointment for 2 years.</li>
<li><strong>Location:</strong> Prague (Czech Republic), London (United Kingdom), or San Francisco Bay Area (United States). The project is built to be online-first.</li>
<li><strong>Compensation:</strong> $80-300k USD based on location and experience.</li>
<li><strong>Benefits:</strong> Research budget for compute and travel, flexible work arrangements, and intellectual freedom.</li>
</ul>
<h3>How to Apply</h3>
<p>To apply, please submit the following by <strong>October 15th</strong>:</p>
<ul>
<li><strong>Cover Letter</strong> (max 2 pages) explaining why you are applying, how you would technically approach an experimental idea (e.g., 'Infectious Mindsets'), and how your past work makes you a strong fit.</li>
<li><strong>CV</strong>.</li>
<li><strong>Work Sample:</strong> Your strongest first-author publication or GitHub repo.</li>
</ul>
<p>The preferred start date is December 2025 or January 2026.</p>
<p><a href="https://forms.gle/JxMbd9WBP6DiRezQA">Apply</a></p>5:["path","hiring","c"]
0:["zs6up-Y-ej89dc_N4UXG-",[[["",{"children":[["path","hiring","c"],{"children":["__PAGE__?{\"path\":[\"hiring\"]}",{}]}]},"$undefined","$undefined",true],["",{"children":[["path","hiring","c"],{"children":["__PAGE__",{},[["$L1",["$","div",null,{"className":"h-screen","children":[["$","$L2",null,{"root":false}],["$","div",null,{"className":"container prose Content_content__bGfAW","children":[["$","h1",null,{"className":"pt-8","children":"Open Positions"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$3"}}]]}],["$","footer",null,{"className":"footer-container","children":[["$","div",null,{"className":"footer-divider"}],["$","div",null,{"className":"footer-column-logo","children":["$","img",null,{"className":"footer-logo","src":"/cuni.png","alt":"CUNI Logo"}]}],["$","div",null,{"className":"footer-columns","children":[["$","div",null,{"className":"footer-subcolumn","children":["Academic part of ACS research group is part of"," ",["$","a",null,{"href":"http://www.cts.cuni.cz/en","children":"Center for Theoretical Study"}]," at"," ",["$","a",null,{"href":"https://cuni.cz/en","children":"Charles University in Prague."}]," "," ","ACS research program is also supported by Epistea zs."]}],["$","div",null,{"className":"footer-subcolumn","children":[["$","div",null,{"className":"footer-contact-line","children":[["$","span",null,{"style":{"float":"left","padding":"0 0.5em 1.3em 0"},"children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 512 512","style":{"display":"inline","height":"1em"},"children":["$","path",null,{"d":"M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48H48zM0 176V384c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V176L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z"}]}]}],"Husova 4",["$","br",null,{}],"110 00 Prague, CZ"]}],["$","div",null,{"className":"footer-contact-line","children":["$","a",null,{"href":"mailto:contact@acsresearch.org","children":[["$","span",null,{"style":{"padding":"0 0.5em 0 0"},"children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 512 512","style":{"display":"inline","height":"1em"},"children":["$","path",null,{"d":"M256 64C150 64 64 150 64 256s86 192 192 192c17.7 0 32 14.3 32 32s-14.3 32-32 32C114.6 512 0 397.4 0 256S114.6 0 256 0S512 114.6 512 256v32c0 53-43 96-96 96c-29.3 0-55.6-13.2-73.2-33.9C320 371.1 289.5 384 256 384c-70.7 0-128-57.3-128-128s57.3-128 128-128c27.9 0 53.7 8.9 74.7 24.1c5.7-5 13.1-8.1 21.3-8.1c17.7 0 32 14.3 32 32v80 32c0 17.7 14.3 32 32 32s32-14.3 32-32V256c0-106-86-192-192-192zm64 192a64 64 0 1 0 -128 0 64 64 0 1 0 128 0z"}]}]}],"contact@acsresearch.org"]}]}],["$","div",null,{"className":"footer-contact-line","children":["$","a",null,{"href":"https://twitter.com/acsresearchorg","children":[["$","span",null,{"style":{"padding":"0 0.5em 0 0"},"children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 512 512","style":{"display":"inline","height":"1em"},"children":["$","path",null,{"d":"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"}]}]}],"@acsresearchorg"]}]}]]}]]}]]}]]}]],null],null]},["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","$5","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/c70e259a19bc14f0.css","precedence":"next","crossOrigin":"$undefined"}]]}],null]},[["$","html",null,{"lang":"en","children":["$","$7",null,{"children":["$","body",null,{"className":"font-serif","children":[["$","$8",null,{"children":["$","$L9",null,{}]}],["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L6",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/a6a7d77a57a1ff75.css","precedence":"next","crossOrigin":"$undefined"}]],"$La"]]]]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Alignment of Complex Systems Research Group – Open Positions"}],["$","link","3",{"rel":"icon","href":"/icon.png"}]]
1:null
