<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/cuni.png"/><link rel="stylesheet" href="/_next/static/css/b6de2557c2ec92a9.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/29228a16112744e1.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-e05bc6388b4a0ef3.js" crossorigin=""/><script src="/_next/static/chunks/30b509c0-21f56f552f856b55.js" async="" crossorigin=""></script><script src="/_next/static/chunks/184-3b94349de5dc598d.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-198def3c3364b349.js" async="" crossorigin=""></script><script src="/_next/static/chunks/908-fd4f59040d8bb9b0.js" async=""></script><script src="/_next/static/chunks/922-4093337dd159fc08.js" async=""></script><script src="/_next/static/chunks/app/%5B...path%5D/page-edee1d5a7778fd2b.js" async=""></script><script src="/_next/static/chunks/app/layout-72e741dea45ff53a.js" async=""></script><title>Alignment of Complex Systems Research Group – ACS Research Program</title><link rel="icon" href="/icon.png"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body class="font-serif"><!--$--><!--/$--><div class="h-screen"><header class="Header_header__MvnS2 Header_open-false__J8RUh"><div class="h-0 relative"><h1 class="undefined Header_abbr-other__uRTpH"><a href="/">ACS</a></h1></div><span class="Header_burger__CUvUF">☰</span><nav class="Header_nav__EE71E"><a href="/about">ABOUT</a><span class="Header_dotsep__AsvCj">•</span><a href="/research">RESEARCH</a><span class="Header_dotsep__AsvCj">•</span><a href="/posts">POSTS</a><span class="Header_dotsep__AsvCj">•</span><a href="/team">TEAM</a><span class="Header_dotsep__AsvCj">•</span><a href="/contact">CONTACT</a></nav></header><div class="container prose Content_content__bGfAW"><h1 class="pt-8">ACS Research Program</h1><div><p>Our research seeks to build towards the following goals:</p>
<ul>
<li>A science of the space of intelligent systems</li>
<li>Naturalised theories of agency, including theories that account for the multi-scale nature of agentic behaviour</li>
<li>Nuanced accounts of how humans reason, act and value as it pertains to solving the AI alignment problem</li>
<li>An understanding of the underlying principles that govern collective behaviour between humans, between humans and AIs, and between AI systems</li>
</ul>
<h2>A science of the space of intelligent systems</h2>
<p>We seek to build systematic understanding of which properties of intelligent behaviour are universal, convergent or local across a wide range of systems, scales and substrates. This understanding forms the basis for asking the right sorts of questions about the risks, potentials and design imperatives of advanced AI systems.</p>
<p>To this end, we draw on a range of sophisticated thinking that has already been done, including in evolutionary biology, cognitive science, statistical physics, economics, ecology, cybernetics and information theory. By integrating and build on these traditions, we aim to better understand the trajectory space for advanced AI systems.</p>
<h2>Hierarchical Agency</h2>
<p>Over the past 100 or so years, a large amount of maths has been developed (most of it under the name of Game Theory) to help us describe the <em>relations between agents at the same level of analysis.</em> At the same time, many systems have several levels of analysis at which their behaviour could be sensibly described and explained. For instance, we can usefully model a company as an agent, or its employees; a social movement, or its followers; a nation-state, or its political class; etc.</p>
<p>At ACS, we aim to develop a conceptual framework, which can help us reason about the <em>relations between agents at different levels of analysis,</em> i.e. between superagents and their subagents. What we want is a formalism which is good for thinking about both upward and downward intentionality - something akin to ‘vertical game theory’ or a ‘theory of hierarchical agency’. We believe this understanding is critical to building and integrating AI systems into human socio-economic and political structures in a way that is safe and aligned.</p>
<h2>Realistic Accounts of how Humans Reason and Value</h2>
<p>‘Alignment’ or ‘safety’ are properties defined at the interface between a system and its environment, rather than properties intrinsic to a system in isolation. As such, it matters to understand the structural and functional properties of both the system that is to be aligned, as well as what we are aligning it to. However, we could pick out several plausible candidates as targets for what we want to align AI systems to–from individual humans to human groups. In addition, humans, importantly, are not accurately described by fixed or latent utility and belief functions, as the classical rational agent model suggests. Overall, current theorising on the appropriate targets of alignment and their structural properties is inadequate for understanding the subtleties that arise when tackling the problem of AI alignment.</p>
<p>ACS works on developing AI alignment proposals which are based on a realistic understanding of how humans reason and value in practice and which recognize the hierarchical relationships between these target systems is critical to solving the problem and not something which can be postponed or delegated to AI systems.</p>
<h2>Ecosystems of Intelligence</h2>
<p>Consider not just one powerful AGI, or several, but an entire ecosystem of different AI and human-AI systems and services varying in power, specialisation, and agency. From here, we can investigate questions about convergent or contingent properties of such ecosystems, what shapes their trajectory through time, as well as their strategic implications. For example, a period where human-AI teams are more capable than either humans or AI systems on their own might provide a critical window during which we can shape the nature of subsequent, more powerful systems and the institutions and protocols which shape their interactions. ACS’s work explores problems of AI risk and safety from the ecosystems perspective.</p>
<h2>Our Publications</h2>
<p><strong>Jan Kulveit</strong>, <strong>Clem von Stengel</strong>, Roman Leventov: <em>Predictive Minds: LLMs As Atypical Active Inference Agents.</em> December 2023, <a href="https://openreview.net/forum?id=bak7hB0Zv9">NeurIPS 2023 SoLaR workshop</a>, <a href="https://arxiv.org/abs/2311.10215">arXiv</a></p>
<p><strong>Nora Ammann</strong>: <em>Value Malleability and its implication for AI alignment.</em> December 2023, NeurIPS 2023 MP<sup>2</sup> workshop</p>
<p>Hardik Rajpal, <strong>Clem von Stengel</strong>, Pedro A. M. Mediano, Fernando E. Rosas, Eduardo Viegas, Pablo A. Marquet, Henrik J. Jensen: <em>Quantifying Hierarchical Selection.</em> November 2023, <a href="https://arxiv.org/abs/2310.20386">arXiv</a></p>
<p><strong>Nora Ammann</strong>, <strong>Clem von Stengel</strong>: <em>A Naturalised Account of Planning in Intelligent Systems.</em> July 2023, <a href="https://direct.mit.edu/isal/proceedings/isal/35/138/116942">Proceedings of ALIFE 2023</a></p></div></div><footer class="footer-container"><div class="footer-divider"></div><div class="footer-column-logo"><img class="footer-logo" src="/cuni.png" alt="CUNI Logo"/></div><div class="footer-columns"><div class="footer-subcolumn">ACS research group is part of<!-- --> <a href="http://www.cts.cuni.cz/en">Center for Theoretical Study</a> at<!-- --> <a href="https://cuni.cz/en">Charles University in Prague.</a></div><div class="footer-subcolumn"><div class="footer-contact-line"><span style="float:left;padding:0 0.5em 1.3em 0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="display:inline;height:1em"><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48H48zM0 176V384c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V176L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z"></path></svg></span>Husova 4<br/>110 00 Prague, CZ</div><div class="footer-contact-line"><a href="mailto:contact@acsresearch.org"><span style="padding:0 0.5em 0 0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="display:inline;height:1em"><path d="M256 64C150 64 64 150 64 256s86 192 192 192c17.7 0 32 14.3 32 32s-14.3 32-32 32C114.6 512 0 397.4 0 256S114.6 0 256 0S512 114.6 512 256v32c0 53-43 96-96 96c-29.3 0-55.6-13.2-73.2-33.9C320 371.1 289.5 384 256 384c-70.7 0-128-57.3-128-128s57.3-128 128-128c27.9 0 53.7 8.9 74.7 24.1c5.7-5 13.1-8.1 21.3-8.1c17.7 0 32 14.3 32 32v80 32c0 17.7 14.3 32 32 32s32-14.3 32-32V256c0-106-86-192-192-192zm64 192a64 64 0 1 0 -128 0 64 64 0 1 0 128 0z"></path></svg></span>contact@acsresearch.org</a></div><div class="footer-contact-line"><a href="https://twitter.com/acsresearchorg"><span style="padding:0 0.5em 0 0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="display:inline;height:1em"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></span>@acsresearchorg</a></div></div></div></footer></div><script src="/_next/static/chunks/webpack-e05bc6388b4a0ef3.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/b6de2557c2ec92a9.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/29228a16112744e1.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"4:I[9070,[],\"\"]\n6:I[3542,[\"908\",\"static/chunks/908-fd4f59040d8bb9b0.js\",\"922\",\"static/chunks/922-4093337dd159fc08.js\",\"884\",\"static/chunks/app/%5B...path%5D/page-edee1d5a7778fd2b.js\"],\"\"]\n8:I[2070,[],\"\"]\na:I[8932,[],\"\"]\nb:\"$Sreact.strict_mode\"\nc:\"$Sreact.suspense\"\nd:I[5176,[\"908\",\"static/chunks/908-fd4f59040d8bb9b0.js\",\"185\",\"static/chunks/app/layout-72e741dea45ff53a.js\"],\"\"]\nf:I[4357,[],\"\"]\n7:T14d5,"])</script><script>self.__next_f.push([1,"\u003cp\u003eOur research seeks to build towards the following goals:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA science of the space of intelligent systems\u003c/li\u003e\n\u003cli\u003eNaturalised theories of agency, including theories that account for the multi-scale nature of agentic behaviour\u003c/li\u003e\n\u003cli\u003eNuanced accounts of how humans reason, act and value as it pertains to solving the AI alignment problem\u003c/li\u003e\n\u003cli\u003eAn understanding of the underlying principles that govern collective behaviour between humans, between humans and AIs, and between AI systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eA science of the space of intelligent systems\u003c/h2\u003e\n\u003cp\u003eWe seek to build systematic understanding of which properties of intelligent behaviour are universal, convergent or local across a wide range of systems, scales and substrates. This understanding forms the basis for asking the right sorts of questions about the risks, potentials and design imperatives of advanced AI systems.\u003c/p\u003e\n\u003cp\u003eTo this end, we draw on a range of sophisticated thinking that has already been done, including in evolutionary biology, cognitive science, statistical physics, economics, ecology, cybernetics and information theory. By integrating and build on these traditions, we aim to better understand the trajectory space for advanced AI systems.\u003c/p\u003e\n\u003ch2\u003eHierarchical Agency\u003c/h2\u003e\n\u003cp\u003eOver the past 100 or so years, a large amount of maths has been developed (most of it under the name of Game Theory) to help us describe the \u003cem\u003erelations between agents at the same level of analysis.\u003c/em\u003e At the same time, many systems have several levels of analysis at which their behaviour could be sensibly described and explained. For instance, we can usefully model a company as an agent, or its employees; a social movement, or its followers; a nation-state, or its political class; etc.\u003c/p\u003e\n\u003cp\u003eAt ACS, we aim to develop a conceptual framework, which can help us reason about the \u003cem\u003erelations between agents at different levels of analysis,\u003c/em\u003e i.e. between superagents and their subagents. What we want is a formalism which is good for thinking about both upward and downward intentionality - something akin to ‘vertical game theory’ or a ‘theory of hierarchical agency’. We believe this understanding is critical to building and integrating AI systems into human socio-economic and political structures in a way that is safe and aligned.\u003c/p\u003e\n\u003ch2\u003eRealistic Accounts of how Humans Reason and Value\u003c/h2\u003e\n\u003cp\u003e‘Alignment’ or ‘safety’ are properties defined at the interface between a system and its environment, rather than properties intrinsic to a system in isolation. As such, it matters to understand the structural and functional properties of both the system that is to be aligned, as well as what we are aligning it to. However, we could pick out several plausible candidates as targets for what we want to align AI systems to–from individual humans to human groups. In addition, humans, importantly, are not accurately described by fixed or latent utility and belief functions, as the classical rational agent model suggests. Overall, current theorising on the appropriate targets of alignment and their structural properties is inadequate for understanding the subtleties that arise when tackling the problem of AI alignment.\u003c/p\u003e\n\u003cp\u003eACS works on developing AI alignment proposals which are based on a realistic understanding of how humans reason and value in practice and which recognize the hierarchical relationships between these target systems is critical to solving the problem and not something which can be postponed or delegated to AI systems.\u003c/p\u003e\n\u003ch2\u003eEcosystems of Intelligence\u003c/h2\u003e\n\u003cp\u003eConsider not just one powerful AGI, or several, but an entire ecosystem of different AI and human-AI systems and services varying in power, specialisation, and agency. From here, we can investigate questions about convergent or contingent properties of such ecosystems, what shapes their trajectory through time, as well as their strategic implications. For example, a period where human-AI teams are more capable than either humans or AI systems on their own might provide a critical window during which we can shape the nature of subsequent, more powerful systems and the institutions and protocols which shape their interactions. ACS’s work explores problems of AI risk and safety from the ecosystems perspective.\u003c/p\u003e\n\u003ch2\u003eOur Publications\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eJan Kulveit\u003c/strong\u003e, \u003cstrong\u003eClem von Stengel\u003c/strong\u003e, Roman Leventov: \u003cem\u003ePredictive Minds: LLMs As Atypical Active Inference Agents.\u003c/em\u003e December 2023, \u003ca href=\"https://openreview.net/forum?id=bak7hB0Zv9\"\u003eNeurIPS 2023 SoLaR workshop\u003c/a\u003e, \u003ca href=\"https://arxiv.org/abs/2311.10215\"\u003earXiv\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNora Ammann\u003c/strong\u003e: \u003cem\u003eValue Malleability and its implication for AI alignment.\u003c/em\u003e December 2023, NeurIPS 2023 MP\u003csup\u003e2\u003c/sup\u003e workshop\u003c/p\u003e\n\u003cp\u003eHardik Rajpal, \u003cstrong\u003eClem von Stengel\u003c/strong\u003e, Pedro A. M. Mediano, Fernando E. Rosas, Eduardo Viegas, Pablo A. Marquet, Henrik J. Jensen: \u003cem\u003eQuantifying Hierarchical Selection.\u003c/em\u003e November 2023, \u003ca href=\"https://arxiv.org/abs/2310.20386\"\u003earXiv\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eNora Ammann\u003c/strong\u003e, \u003cstrong\u003eClem von Stengel\u003c/strong\u003e: \u003cem\u003eA Naturalised Account of Planning in Intelligent Systems.\u003c/em\u003e July 2023, \u003ca href=\"https://direct.mit.edu/isal/proceedings/isal/35/138/116942\"\u003eProceedings of ALIFE 2023\u003c/a\u003e\u003c/p\u003e"])</script><script>self.__next_f.push([1,"9:[\"path\",\"research\",\"c\"]\n10:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/b6de2557c2ec92a9.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"8EldxgVSJ-ug7vJW9p909\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/research\",\"initialTree\":[\"\",{\"children\":[[\"path\",\"research\",\"c\"],{\"children\":[\"__PAGE__?{\\\"path\\\":[\\\"research\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"path\",\"research\",\"c\"],{\"children\":[\"__PAGE__\",{},[\"$L5\",[\"$\",\"div\",null,{\"className\":\"h-screen\",\"children\":[[\"$\",\"$L6\",null,{\"root\":false}],[\"$\",\"div\",null,{\"className\":\"container prose Content_content__bGfAW\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"pt-8\",\"children\":\"ACS Research Program\"}],[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$7\"}}]]}],[\"$\",\"footer\",null,{\"className\":\"footer-container\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-divider\"}],[\"$\",\"div\",null,{\"className\":\"footer-column-logo\",\"children\":[\"$\",\"img\",null,{\"className\":\"footer-logo\",\"src\":\"/cuni.png\",\"alt\":\"CUNI Logo\"}]}],[\"$\",\"div\",null,{\"className\":\"footer-columns\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-subcolumn\",\"children\":[\"ACS research group is part of\",\" \",[\"$\",\"a\",null,{\"href\":\"http://www.cts.cuni.cz/en\",\"children\":\"Center for Theoretical Study\"}],\" at\",\" \",[\"$\",\"a\",null,{\"href\":\"https://cuni.cz/en\",\"children\":\"Charles University in Prague.\"}]]}],[\"$\",\"div\",null,{\"className\":\"footer-subcolumn\",\"children\":[[\"$\",\"div\",null,{\"className\":\"footer-contact-line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"float\":\"left\",\"padding\":\"0 0.5em 1.3em 0\"},\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 512 512\",\"style\":{\"display\":\"inline\",\"height\":\"1em\"},\"children\":[\"$\",\"path\",null,{\"d\":\"M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4L236.8 313.6c11.4 8.5 27 8.5 38.4 0L492.8 150.4c12.1-9.1 19.2-23.3 19.2-38.4c0-26.5-21.5-48-48-48H48zM0 176V384c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V176L294.4 339.2c-22.8 17.1-54 17.1-76.8 0L0 176z\"}]}]}],\"Husova 4\",[\"$\",\"br\",null,{}],\"110 00 Prague, CZ\"]}],[\"$\",\"div\",null,{\"className\":\"footer-contact-line\",\"children\":[\"$\",\"a\",null,{\"href\":\"mailto:contact@acsresearch.org\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"padding\":\"0 0.5em 0 0\"},\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 512 512\",\"style\":{\"display\":\"inline\",\"height\":\"1em\"},\"children\":[\"$\",\"path\",null,{\"d\":\"M256 64C150 64 64 150 64 256s86 192 192 192c17.7 0 32 14.3 32 32s-14.3 32-32 32C114.6 512 0 397.4 0 256S114.6 0 256 0S512 114.6 512 256v32c0 53-43 96-96 96c-29.3 0-55.6-13.2-73.2-33.9C320 371.1 289.5 384 256 384c-70.7 0-128-57.3-128-128s57.3-128 128-128c27.9 0 53.7 8.9 74.7 24.1c5.7-5 13.1-8.1 21.3-8.1c17.7 0 32 14.3 32 32v80 32c0 17.7 14.3 32 32 32s32-14.3 32-32V256c0-106-86-192-192-192zm64 192a64 64 0 1 0 -128 0 64 64 0 1 0 128 0z\"}]}]}],\"contact@acsresearch.org\"]}]}],[\"$\",\"div\",null,{\"className\":\"footer-contact-line\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://twitter.com/acsresearchorg\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"padding\":\"0 0.5em 0 0\"},\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"viewBox\":\"0 0 512 512\",\"style\":{\"display\":\"inline\",\"height\":\"1em\"},\"children\":[\"$\",\"path\",null,{\"d\":\"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z\"}]}]}],\"@acsresearchorg\"]}]}]]}]]}]]}]]}],null]]},[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$9\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/29228a16112744e1.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"$b\",null,{\"children\":[\"$\",\"body\",null,{\"className\":\"font-serif\",\"children\":[[\"$\",\"$c\",null,{\"children\":[\"$\",\"$Ld\",null,{}]}],[\"$\",\"$L8\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]]}]}]}],null]],\"initialHead\":[false,\"$Le\"],\"globalErrorComponent\":\"$f\",\"missingSlots\":\"$W10\"}]]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Alignment of Complex Systems Research Group – ACS Research Program\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/icon.png\"}]]\n5:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>